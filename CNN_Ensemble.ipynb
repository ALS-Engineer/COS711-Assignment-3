{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Ensemble.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YGnj7NLy8bfb",
        "b0-fgS1F8zlW",
        "AZiFOrWB8-Gg",
        "ws0mHsbZ9gxc",
        "P9M6bJW5w6vv",
        "WwXkcr05MWze",
        "ZLUOwH1I9tRT"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGnj7NLy8bfb",
        "colab_type": "text"
      },
      "source": [
        "# **Install**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqcC9Aoj7Gxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip3 install ax-platform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "almJsHV18fVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlnYLTXa8hb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check GPU\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0-fgS1F8zlW",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_P7wqKg8xWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# General\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import statistics\n",
        "import pandas as pd\n",
        "sns.set()\n",
        "\n",
        "# keras imports\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, InputLayer, Conv1D, Flatten, MaxPool1D, BatchNormalization, MaxPooling1D\n",
        "from keras.layers import PReLU \n",
        "from keras.initializers import glorot_uniform\n",
        "from keras import optimizers\n",
        "\n",
        "# sklearn imports\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import  MinMaxScaler,StandardScaler\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Ax-platform imports\n",
        "from ax.service.ax_client import AxClient\n",
        "from ax.utils.notebook.plotting import render, init_notebook_plotting\n",
        "\n",
        "plt.rcParams.update({\n",
        "                     'axes.titlesize'  : 22,\n",
        "                     'xtick.labelsize' : 12,\n",
        "                     'ytick.labelsize' : 12,\n",
        "                     'axes.labelsize'  : 16\n",
        "                     })\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (10,6) \n",
        "plt.rcParams[\"font.family\"] = \"Serif\"\n",
        "plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']\n",
        "# plt.rcParams.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZiFOrWB8-Gg",
        "colab_type": "text"
      },
      "source": [
        "# Data and Scaling Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTr0JbJ687Vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colab_dir = '/content/drive/My Drive/Colab Notebooks/COS 711 Assignment 3/data/data_cleaned_means.csv'\n",
        "df = pd.read_csv(colab_dir)\n",
        "\n",
        "print(df['target'].describe())\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.distplot(df['target'], color='g', bins=100, hist_kws={'alpha': 0.4})\n",
        "\n",
        "df.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYi1pQli9DfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################ Setting up Data and Target ###################################################################\n",
        "X = df.drop(columns=['Unnamed: 0','ID','location','target','temp', 'precip', 'rel_humidity', 'wind_dir','wind_spd', 'atmos_press','location']) # ,'temp', 'precip', 'rel_humidity', 'wind_dir','wind_spd', 'atmos_press', ,'index'\n",
        "y = df['target']\n",
        "###########################################################################################################################\n",
        "y = np.log(y)\n",
        "y = np.array(y)\n",
        "y = y.reshape(-1,1)\n",
        "# # scalery = StandardScaler().fit(y)\n",
        "# scalery = MinMaxScaler().fit(y)\n",
        "# y = scalery.transform(y)\n",
        "############################ SPLITTING DATA ######### #####################################################################\n",
        "val_per = 0.2\n",
        "test_per = 0.1\n",
        "\n",
        "validation = X.shape[0]*val_per\n",
        "testing = X.shape[0]*test_per\n",
        "training = X.shape[0] - validation - testing\n",
        "\n",
        "X_remain, X_test, y_remain, y_test = train_test_split(X, y, test_size=test_per, random_state=42)\n",
        "per = 1-(training/X_remain.shape[0])\n",
        "X_train,X_val,y_train,y_val =  train_test_split(X_remain, y_remain, test_size=per, random_state=42)\n",
        "\n",
        "\n",
        "scalerX_remain = StandardScaler().fit(X_remain)\n",
        "X_remain = scalerX_remain.transform(X_remain)\n",
        "\n",
        "scalerX_train = StandardScaler().fit(X_train)\n",
        "scalerX_val = StandardScaler().fit(X_val)\n",
        "scalerX_test = StandardScaler().fit(X_test)\n",
        "X_train = scalerX_train.transform(X_train)\n",
        "X_val = scalerX_val.transform(X_val)\n",
        "X_test = scalerX_test.transform(X_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "X_remain = X_remain.reshape(X_remain.shape[0], X_remain.shape[1], 1)\n",
        "\n",
        "\n",
        "# # DOING THIS FOR ZINDI SUBMISSION # COMMENT THIS OUT and UNCOMMENT ABOVE TO RUN ASSIGNMENT INVESTIGATION\n",
        "# X_train,X_val,y_train,y_val =  train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# scalerX_train = StandardScaler().fit(X_train)\n",
        "# scalerX_val = StandardScaler().fit(X_val)\n",
        "# X_train = scalerX_train.transform(X_train)\n",
        "# X_val = scalerX_val.transform(X_val)\n",
        "# scalerX = StandardScaler().fit(X)\n",
        "# X = scalerX.transform(X)\n",
        "\n",
        "\n",
        "# X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "# X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
        "# X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "print('X_train shape : ',X_train.shape)\n",
        "print('X_val shape : ',X_val.shape)\n",
        "# print('X shape : ',X.shape)\n",
        "print('X_remain shape : ',X_remain.shape)\n",
        "print('X_test shape : ',X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws0mHsbZ9gxc",
        "colab_type": "text"
      },
      "source": [
        "# Model Buidling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMSuI5XNDg-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn(num_filters,num_kernels,pools,neurons):\n",
        "  model_m = Sequential()\n",
        "  model_m.add(Conv1D(filters = num_filters, kernel_size = num_kernels, activation = 'relu', input_shape = (X_train.shape[1],X_train.shape[2])))\n",
        "  model_m.add(Conv1D(filters = num_filters, kernel_size = num_kernels, activation = 'relu', input_shape = (X_train.shape[1],X_train.shape[2])))\n",
        "  model_m.add(Conv1D(filters = num_filters, kernel_size = num_kernels, activation = 'relu', input_shape = (X_train.shape[1],X_train.shape[2])))\n",
        "  model_m.add(Conv1D(filters = num_filters, kernel_size = num_kernels, activation = 'relu', input_shape = (X_train.shape[1],X_train.shape[2])))\n",
        "  model_m.add(Conv1D(filters = num_filters, kernel_size = num_kernels, activation = 'relu', input_shape = (X_train.shape[1],X_train.shape[2])))\n",
        "  model_m.add(Conv1D(filters = num_filters, kernel_size = num_kernels, activation = 'relu', input_shape = (X_train.shape[1],X_train.shape[2])))\n",
        "  model_m.add(MaxPooling1D(pool_size = pools))\n",
        "  model_m.add(Flatten())\n",
        "  model_m.add(Dense(neurons, activation = 'relu'))\n",
        "  model_m.add(Dense(1,activation = 'linear'))\n",
        "  return model_m\n",
        "\n",
        "def cnn_cv_score(parametrization, weight = None):\n",
        "  model = cnn(parametrization.get('num_filters'),\n",
        "              parametrization.get('num_kernels'),\n",
        "              parametrization.get('pools'),\n",
        "              parametrization.get('neurons'))\n",
        "  \n",
        "  learning_rate = parametrization.get('learning_rate')\n",
        "  batch_size = parametrization.get('batch_size')\n",
        "\n",
        "  model.compile(optimizer = optimizers.RMSprop(learning_rate = learning_rate), loss='mse', metrics = ['mse'])\n",
        "  history = model.fit(X_train, y_train, epochs = NUM_EPOCHS,batch_size = batch_size, validation_data = (X_val,y_val))\n",
        "\n",
        "  last10_scores = np.array(history.history['val_mse'][-10:])\n",
        "  mean = last10_scores.mean()\n",
        "  sem = last10_scores.std()\n",
        "\n",
        "  if np.isnan(mean):\n",
        "    return 9999.0, 0.0\n",
        "\n",
        "  return mean, sem\n",
        "\n",
        "\n",
        "NUM_EPOCHS = 15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YUkRv5RJ97J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = [\n",
        "              {\n",
        "                  \"name\" : \"num_filters\",\n",
        "                  \"type\" : \"choice\",\n",
        "                  \"values\" : [16,32,64],\n",
        "              },\n",
        "              {\n",
        "                  \"name\" : \"num_kernels\",\n",
        "                  \"type\" : \"choice\",\n",
        "                  \"values\" : [2,3],\n",
        "              },\n",
        "              {\n",
        "                  \"name\" : \"pools\",\n",
        "                  \"type\" : \"choice\",\n",
        "                  \"values\" : [2,3,4,5],\n",
        "              },\n",
        "              {\n",
        "                  \"name\": \"neurons\",\n",
        "                  \"type\": \"range\",\n",
        "                  # \"bounds\": [20,100],\n",
        "                  \"bounds\": [70,95],\n",
        "                  \"value_type\": \"int\",\n",
        "              },\n",
        "              {\n",
        "                  \"name\": \"batch_size\",\n",
        "                  \"type\": \"choice\",\n",
        "                  # \"values\": [32, 64, 128, 256]\n",
        "                  \"values\": [32,64]\n",
        "              },\n",
        "              {\n",
        "                  \"name\" : \"learning_rate\",\n",
        "                  \"type\" : \"range\",\n",
        "                  \"bounds\" : [0.0001, 0.5],\n",
        "                  \"log_scale\": True,\n",
        "              }\n",
        "]\n",
        "\n",
        "init_notebook_plotting()\n",
        "ax_client = AxClient()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L5VbiMILHMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "number_of_experiments = 80\n",
        "\n",
        "ax_client.create_experiment(\n",
        "    name=\"keras_experiment\",\n",
        "    parameters=parameters,\n",
        "    objective_name='keras_cv',\n",
        "    minimize=True)\n",
        "\n",
        "def evaluate(parameters):\n",
        "    return {\"keras_cv\": cnn_cv_score(parameters)}\n",
        "\n",
        "for i in range(number_of_experiments + 1):\n",
        "    parameters, trial_index = ax_client.get_next_trial()\n",
        "    ax_client.complete_trial(trial_index=trial_index, raw_data=evaluate(parameters))\n",
        "ax_client.get_trials_data_frame().sort_values('trial_index')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrVSupsmvWQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_parameters, values = ax_client.get_best_parameters()\n",
        "# the best set of parameters.\n",
        "best = []\n",
        "for k in best_parameters.items():\n",
        "  best.append(k)\n",
        "  print(k)\n",
        "\n",
        "print()\n",
        "\n",
        "# the best score achieved.\n",
        "means, covariances = values\n",
        "print(means)\n",
        "print(covariances)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSbbQiViLHHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_best_cnn_model(best_parameters):  \n",
        "  model = cnn(best_parameters['num_filters'], \n",
        "              best_parameters['num_kernels'], \n",
        "              best_parameters['pools'],\n",
        "              best_parameters['neurons'])\n",
        "  model.compile(optimizer = optimizers.RMSprop(learning_rate = best_parameters['learning_rate']), loss = 'mse', metrics = ['mse'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQBhbbwxH34h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = best_parameters['batch_size']\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "model = build_best_cnn_model(best_parameters)\n",
        "history = model.fit(X_train, y_train, epochs = NUM_EPOCHS,batch_size = batch_size, validation_data = (X_val,y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S9XFhX2IVNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lift Chart\n",
        "def chart_regression(pred,y,sort=True):\n",
        "  t = pd.DataFrame({'pred':pred.flatten(), 'y': y.flatten()})\n",
        "  if sort :\n",
        "    t.sort_values(by = ['y'],inplace=True)\n",
        "    plt.title('Lift Chart (Test Set)',y = 1.05)\n",
        "    plt.plot(t['pred'].tolist(),label='prediction',linewidth = 0.8)\n",
        "    plt.plot(t['y'].tolist(),label='expected',linewidth = 3)\n",
        "    plt.xlabel('Sorted Test Set (Ascending Order)')\n",
        "    plt.ylabel('Air Quality')\n",
        "    plt.legend(loc = 'best',fontsize = 16)\n",
        "    plt.show()\n",
        "\n",
        "data   = X_test\n",
        "labels = y_test\n",
        "\n",
        "y_pred_no_ensemble = model.predict(data)\n",
        "y_new_inverse_no_ensemble = np.exp(y_pred_no_ensemble)\n",
        "y_real_inverse = np.exp(labels)\n",
        "plt.figure(1)\n",
        "plt.title('Prediction vs Actual (Test Set)',y = 1.05)\n",
        "plt.scatter(y_real_inverse,y_new_inverse_no_ensemble,alpha = 0.6)\n",
        "plt.plot([0,375],[0,375],'k--',linewidth = 3)\n",
        "plt.xlabel('Test Set')\n",
        "plt.ylabel('Predictions')\n",
        "plt.xlim([0,375])\n",
        "plt.ylim([0,375])\n",
        "\n",
        "score = metrics.mean_squared_error(y_new_inverse_no_ensemble,y_real_inverse)\n",
        "score_mae = metrics.median_absolute_error(y_new_inverse_no_ensemble,y_real_inverse)\n",
        "print('MAE : ',score_mae)\n",
        "print('RMSE : ',np.sqrt(score))\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(2)\n",
        "chart_regression(y_new_inverse_no_ensemble,y_real_inverse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9M6bJW5w6vv",
        "colab_type": "text"
      },
      "source": [
        "# Ensemble Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW18MrQdw6cM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ab94d20-f9b9-4592-afe2-ce0befb59983"
      },
      "source": [
        "NUM_EPOCHS = 50\n",
        "batch_size = best_parameters['batch_size']\n",
        "\n",
        "n_splits = 15\n",
        "kfolds = KFold(n_splits = n_splits ,shuffle = True,random_state = 42)\n",
        "kfolds.get_n_splits(X_remain)\n",
        "# kfolds.get_n_splits(X) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQv6R9L2w6N6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = []\n",
        "models = []\n",
        "current_fold = 1\n",
        "for train,test in kfolds.split(X_remain):\n",
        "# for train,test in kfolds.split(X):\n",
        "  print('commencing fold {}:'.format(current_fold))\n",
        "  print('  preparing data...')\n",
        "  Xt = X_remain[train]\n",
        "  Yt = y_remain[train]\n",
        "  Xv = X_remain[test]\n",
        "  Yv = y_remain[test] \n",
        "\n",
        "  # Xt = X[train]\n",
        "  # Yt = y[train]\n",
        "  # Xv = X[test]\n",
        "  # Yv = y[test] \n",
        "\n",
        "  print(len(train))\n",
        "  print(len(test))\n",
        "  print()\n",
        "\n",
        "  # create, fit and test model\n",
        "  print('  building model...')\n",
        "  classifier = build_best_cnn_model(best_parameters)\n",
        "  print('  fitting model...')\n",
        "  classifier.fit(Xt, Yt, epochs=NUM_EPOCHS, batch_size=batch_size)\n",
        "  print('  evaluating model...')\n",
        "  score = classifier.evaluate(Xv, Yv, batch_size=batch_size)\n",
        "  \n",
        "  scores.append(score[-1])\n",
        "  models.append(classifier)\n",
        "\n",
        "  print('  fold {} mse: {}'.format(current_fold, score[-1]))\n",
        "  current_fold += 1\n",
        "\n",
        "  print('ensemble mse: {} % (+/- {} %)'.format(np.mean(scores), np.std(scores)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JImektkVxpd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ensemble_predict(data,ensemble_models):\n",
        "  y_preds = []\n",
        "  for index, classifier in enumerate(ensemble_models):\n",
        "    print('getting predictions from model {}...'.format(index+1))\n",
        "    y_pred = classifier.predict(data, batch_size = batch_size)\n",
        "    y_pred = y_pred.flatten()\n",
        "    y_preds.append(y_pred)\n",
        "  \n",
        "  predictions = np.mean(y_preds,axis = 0)\n",
        "  return predictions.reshape(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpOFn1QtxpPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data   = X_test\n",
        "labels = y_test\n",
        "\n",
        "y_pred_ensemble = ensemble_predict(data,models)\n",
        "y_new_inverse_ensemble = np.exp(y_pred_ensemble)\n",
        "y_real_inverse = np.exp(labels)\n",
        "\n",
        "plt.figure(1)\n",
        "plt.title('Prediction vs Actual (Test Set)',y = 1.05)\n",
        "plt.scatter(y_real_inverse,y_new_inverse_no_ensemble,color = 'r',alpha = 0.6,label = 'CNN')\n",
        "plt.scatter(y_real_inverse,y_new_inverse_ensemble,color = 'b',alpha = 0.6,label = 'Ensemble CNN')\n",
        "plt.plot([0,375],[0,375],'k--',linewidth = 3)\n",
        "plt.xlabel('Test Set')\n",
        "plt.ylabel('Predictions')\n",
        "plt.xlim([0,375])\n",
        "plt.ylim([0,375])\n",
        "plt.legend(loc='best',fontsize = 16)\n",
        "\n",
        "score = metrics.mean_squared_error(y_new_inverse_ensemble,y_real_inverse)\n",
        "score_mae = metrics.median_absolute_error(y_new_inverse_ensemble,y_real_inverse)\n",
        "print('MAE : ',score_mae)\n",
        "print('RMSE : ',np.sqrt(score))\n",
        "\n",
        "plt.figure(2)\n",
        "chart_regression(y_new_inverse_ensemble,y_real_inverse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwXkcr05MWze",
        "colab_type": "text"
      },
      "source": [
        "# Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg9ACX_LMVWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_cnn = build_best_cnn_model(best_parameters)\n",
        "best_cnn.summary()\n",
        "print()\n",
        "best_parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLUOwH1I9tRT",
        "colab_type": "text"
      },
      "source": [
        "# **Zindi Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HZajTkgx0Pb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "\n",
        "colab_dir = '/content/drive/My Drive/Colab Notebooks/COS 711 Assignment 3/data/Test.csv'\n",
        "df_test = pd.read_csv(colab_dir)\n",
        "df_test_dummy = pd.read_csv(colab_dir)\n",
        "\n",
        "Train = df_test\n",
        "# Used for periodic data checks\n",
        "dummy_Train = df_test_dummy\n",
        "\n",
        "# Convert Strings to Numerical Values\n",
        "def replace_nan(x):\n",
        "    if x==\" \":\n",
        "        return np.nan\n",
        "    else :\n",
        "        return float(x)\n",
        "    \n",
        "features=[\"temp\",\"precip\",\"rel_humidity\",\"wind_dir\",\"wind_spd\",\"atmos_press\"]\n",
        "for feature in features : \n",
        "    Train[feature]=Train[feature].apply(lambda x: [ replace_nan(X) for X in x.replace(\"nan\",\" \").split(\",\")])\n",
        "    dummy_Train[feature]=dummy_Train[feature].apply(lambda x: [ replace_nan(X) for X in x.replace(\"nan\",\" \").split(\",\")])\n",
        "\n",
        "# Encoding sensor location (A,B,C,D,E) as Numeric Values (0,1,2,3,4,5)\n",
        "le = preprocessing.LabelEncoder()\n",
        "Train['location'] = le.fit_transform(Train['location'])\n",
        "\n",
        "def aggregate_features(x,col_name):\n",
        "    x[\"max_\"+col_name]=x[col_name].apply(np.max)\n",
        "    x[\"min_\"+col_name]=x[col_name].apply(np.min)\n",
        "    x[\"mean_\"+col_name]=x[col_name].apply(np.mean)\n",
        "    x[\"std_\"+col_name]=x[col_name].apply(np.std)\n",
        "    x[\"var_\"+col_name]=x[col_name].apply(np.var)\n",
        "    x[\"median_\"+col_name]=x[col_name].apply(np.median)\n",
        "    x[\"ptp_\"+col_name]=x[col_name].apply(np.ptp)\n",
        "    return x      \n",
        "def remove_nan_values(x):\n",
        "    return [e for e in x if not math.isnan(e)]\n",
        "\n",
        "for col_name in tqdm(features):\n",
        "    Train[col_name]=Train[col_name].apply(remove_nan_values)\n",
        "for col_name in tqdm(features):\n",
        "    Train = aggregate_features(Train,col_name)\n",
        "\n",
        "# Setting NaN's to the mean of the list\n",
        "type_data = ['temp', 'precip', 'rel_humidity', 'wind_dir','wind_spd', 'atmos_press']\n",
        "for k in range(len(type_data)):\n",
        "    for i in range(len(Train[type_data[k]])):\n",
        "      # Train.at[i,type_data[k]]= pd.Series(dummy_Train[type_data[k]][i]).fillna(np.nanmedian(dummy_Train[type_data[k]][i])).tolist()\n",
        "      Train.at[i,type_data[k]]= pd.Series(dummy_Train[type_data[k]][i]).fillna(np.nanmean(dummy_Train[type_data[k]][i])).tolist()\n",
        "\n",
        "for x in range(121):\n",
        "    Train[\"newtemp\"+ str(x)] = Train.temp.str[x]\n",
        "    Train[\"newprecip\"+ str(x)] = Train.precip.str[x]\n",
        "    Train[\"newrel_humidity\"+ str(x)] = Train.rel_humidity.str[x]\n",
        "    Train[\"newwind_dir\"+ str(x)] = Train.wind_dir.str[x]\n",
        "    Train[\"windspeed\"+ str(x)] = Train.wind_spd.str[x]\n",
        "    Train[\"atmospherepressure\"+ str(x)] = Train.atmos_press.str[x]\n",
        "\n",
        "\n",
        "df_zindi = Train\n",
        "X_zindi = df_zindi.drop(columns=['ID','location','temp', 'precip', 'rel_humidity', 'wind_dir','wind_spd', 'atmos_press','location'])\n",
        "scalerX_zindi = StandardScaler().fit(X_zindi)\n",
        "X_zindi = scalerX_test.transform(X_zindi)\n",
        "X_zindi = X_zindi.reshape(X_zindi.shape[0], X_zindi.shape[1], 1)\n",
        "\n",
        "y_zindi = ensemble_predict(X_zindi,models)\n",
        "y_zindi = np.exp(y_zindi)\n",
        "\n",
        "columns_ID = df_zindi['ID']\n",
        "\n",
        "df = pd.DataFrame(data = y_zindi.flatten() ,columns=['target'])\n",
        "df = df.reset_index()\n",
        "del df['index']\n",
        "\n",
        "df1 = columns_ID\n",
        "df1 = df1.reset_index()\n",
        "del df1['index']\n",
        "\n",
        "submission = pd.concat([df1,df],axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlfUi14qnqx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.to_csv('/content/drive/My Drive/Colab Notebooks/COS 711 Assignment 3/data/submission.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}